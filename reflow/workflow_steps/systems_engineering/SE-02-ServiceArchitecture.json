{
  "step_metadata": {
    "step_id": "SE-02",
    "step_name": "Service Architecture Specification",
    "version": "1.0.0",
    "created_date": "2025-10-26",
    "purpose": "Create UAF-based service_architecture.json for each service with versioning",
    "phase": "architecture",
    "workflow": "01-systems_engineering",
    "maps_from": "Arch-02, Arch-03: Service architecture creation and validation"
  },

  "actions": [
    {
      "action_id": "SE-02-A01",
      "description": "For each service, create VERSIONED service_architecture.json",
      "template": "service_architecture_template.json",
      "versioning": {
        "filename_format": "service_architecture_v{major}.{minor}.{patch}-{YYYYMMDD}.json",
        "initial_version": "v1.0.0-{date}",
        "semantic_versioning": {
          "major": "Breaking interface changes, fundamental architecture changes",
          "minor": "New capabilities, non-breaking interface additions",
          "patch": "Bug fixes, clarifications, documentation improvements"
        },
        "example": "service_architecture_v1.0.0-20251024.json"
      },
      "location_pattern": "specs/machine/service_arch/{service_name}/service_architecture_v1.0.0-{YYYYMMDD}.json",
      "symlink_creation": {
        "create": "service_architecture.json",
        "points_to": "service_architecture_v1.0.0-{YYYYMMDD}.json",
        "purpose": "Tools use symlink to always reference latest version",
        "command": "ln -s service_architecture_v1.0.0-{date}.json service_architecture.json"
      },
      "preservation_rule": "NEVER delete old versions - they are historical record and enable rollback",
      "uaf_compliance": "UAF 1.2 framework",
      "required_sections": [
        "metadata (name, version, description)",
        "operational_view (capabilities, activities, services)",
        "system_view (components, interfaces, data_models)",
        "service_view (service_specs, resources)",
        "constraints (technical, deployment, security)",
        "deployment_architecture (environment, infrastructure)"
      ]
    },
    {
      "action_id": "SE-02-A02",
      "description": "Define component specifications",
      "template": "component_specification_complete_template.json",
      "purpose": "Detailed specification of each component within services",
      "includes": [
        "Component responsibilities",
        "Internal interfaces",
        "Data structures",
        "Business logic"
      ]
    },
    {
      "action_id": "SE-02-A02B",
      "description": "Plan edge weights if framework requires them (CONDITIONAL - based on framework)",
      "condition": {
        "check": "Does selected framework support/require edge weights for flow analysis?",
        "how_to_check": "Read working_memory.json -> framework_analysis.recommended_analyses contains 'flow'",
        "if_true": "Plan edge weight semantics and add to architecture files",
        "if_false": "Skip - framework doesn't use edge weights",
        "frameworks_requiring_weights": {
          "decision_flow": "REQUIRED - Uses transition probabilities (0.0-1.0)",
          "ecological": "REQUIRED - Uses energy transfer rates or biomass flow",
          "systems_biology": "OPTIONAL - Can add reaction rates",
          "social_network": "OPTIONAL - Can add interaction frequencies",
          "uaf": "NOT SUPPORTED - Standard UAF has no edge weight field",
          "complex_adaptive": "OPTIONAL - Can add interaction strengths"
        }
      },
      "purpose": "If framework enables flow analysis, edge weights must be designed into architecture NOW, not added later. Flow analysis will fail without weights.",
      "rationale": "LESSON-03: Edge weights are architectural data, not operational data. They must be planned during architecture design (SE-02), not discovered during graph generation (SE-06). Without weights, flow analysis will fail with 'No capacity attribute' error.",
      "planning_steps": [
        {
          "step": 1,
          "action": "Determine edge weight semantic meaning for your framework",
          "examples": {
            "decision_flow": "probability (0.0-1.0) - likelihood of taking transition",
            "ecological": "energy_transfer_rate (kcal/m²/year) - energy flowing between species",
            "systems_biology": "reaction_rate (s⁻¹) - speed of molecular interaction",
            "social_network": "interaction_frequency (per week) - how often agents interact"
          }
        },
        {
          "step": 2,
          "action": "Add edge weight fields to architecture template",
          "location": "In each architecture file's edges/transitions/interactions section",
          "field_names": {
            "decision_flow": "probability and weight",
            "ecological": "energy_transfer_rate or biomass_flow",
            "systems_biology": "reaction_rate or binding_affinity",
            "social_network": "interaction_frequency or relationship_strength"
          }
        },
        {
          "step": 3,
          "action": "Estimate initial edge weight values",
          "guidance": [
            "Use historical data if available",
            "Use domain expert estimates if no data",
            "Use reasonable defaults if uncertain (e.g., probability=0.5 for unknown branching)",
            "Mark estimates vs. measured values for later refinement"
          ],
          "example_decision_flow": {
            "sequential_step": "probability: 1.0, weight: 10 (always taken)",
            "validation_success": "probability: 0.6, weight: 6 (60% pass)",
            "validation_failure": "probability: 0.4, weight: 4 (40% fail, rework loop)",
            "conditional_branch_A": "probability: 0.7, weight: 7 (70% take path A)",
            "conditional_branch_B": "probability: 0.3, weight: 3 (30% take path B)"
          }
        },
        {
          "step": 4,
          "action": "Document edge weight configuration in working_memory.json",
          "update_fields": {
            "analysis_configuration.edge_weights_included": true,
            "analysis_configuration.edge_weight_semantic": "transition_probability | energy_transfer_rate | reaction_rate | etc.",
            "analysis_configuration.edge_weight_source": "estimated | measured | historical_data | expert_opinion",
            "analysis_configuration.edge_weight_unit": "0.0-1.0 | kcal/m²/year | s⁻¹ | interactions/week"
          }
        },
        {
          "step": 5,
          "action": "Add edge weight examples to architecture files",
          "purpose": "Show developers what values to use when creating architecture specs",
          "example_in_service_architecture": {
            "transitions": [
              {
                "transition_id": "step_A_to_step_B",
                "source": "step_A",
                "target": "step_B",
                "condition": "validation_passed",
                "probability": 0.6,
                "weight": 6,
                "weight_semantic": "Estimated 60% of executions pass validation"
              }
            ]
          }
        }
      ],
      "validation": {
        "check_in_SE-03": "Verify edge weights present if framework requires them",
        "validation_rule": "If working_memory.json -> analysis_configuration.edge_weights_included == true, all edges in architecture files must have weight attribute"
      },
      "common_mistakes": {
        "mistake_1": "Choosing Decision Flow framework but not adding edge weights → Flow analysis fails later",
        "mistake_2": "Adding edge weights during SE-06 (graph generation) → Too late, architecture files already finalized",
        "mistake_3": "Using UAF framework but wanting flow analysis → UAF doesn't support weights, choose different framework"
      },
      "reference": "See docs/NETWORKX_ANALYSIS_GUIDE.md → Edge Weight Planning section"
    },
    {
      "action_id": "SE-02-A03",
      "description": "Define interface registry",
      "template": "interface_registry_enhanced_template.json",
      "location": "specs/machine/interface_registry.json",
      "purpose": "Catalog all interfaces between services and external systems",
      "includes": [
        "Interface definitions",
        "Data contracts",
        "Protocol specifications",
        "Authentication requirements"
      ]
    },
    {
      "action_id": "SE-02-A04",
      "description": "Assign ports and create port registry (CONDITIONAL - only for IT systems)",
      "condition": {
        "check": "framework_registry.json -> frameworks[framework_id].deployment_characteristics.port_management_applicable == true",
        "if_true": "Execute port assignment and create port_registry.json",
        "if_false": "Skip this action - non-IT systems don't need network ports",
        "applicable_frameworks": ["uaf"],
        "not_applicable_frameworks": ["systems_biology", "social_network", "ecological", "complex_adaptive"],
        "custom_framework": "Check deployment_characteristics.port_management_applicable during framework setup"
      },
      "template": "port_registry_template.json",
      "location": "specs/machine/port_registry.json",
      "purpose": "Prevent port conflicts by assigning unique ports to each IT service upfront",
      "rationale": "Port conflicts cause 'Address already in use' errors during deployment. Solving this architecturally prevents operational issues. Only applicable to IT systems with network services.",
      "port_assignment_strategy": {
        "step_1": "Categorize each service (application|internal|data|infrastructure)",
        "step_2": "Assign primary port based on category range (app:8000-8099, internal:8100-8199, etc.)",
        "step_3": "Ensure no duplicate port assignments",
        "step_4": "Assign secondary ports if needed (metrics: 9000+, admin: localhost only)",
        "step_5": "Update each service_architecture.json -> deployment.ports with assigned port",
        "step_6": "Create/update port_registry.json with complete port mapping"
      },
      "port_allocation_examples": {
        "first_application_service": 8000,
        "second_application_service": 8001,
        "first_internal_service": 8100,
        "postgres_database": 5432,
        "redis_cache": 6379,
        "metrics_endpoint_pattern": "primary_port + 1000 (e.g., 8000 → 9000)"
      },
      "validation": {
        "tool": "validate_port_registry.py",
        "run_after_creation": true,
        "must_pass": "No port conflicts allowed before proceeding to development"
      },
      "updates_to_service_architecture": {
        "location": "service_architecture.json -> deployment.ports.primary.port",
        "required_fields": [
          "port (integer)",
          "protocol (HTTP|gRPC|TCP|UDP)",
          "purpose (description)",
          "binding (0.0.0.0 for all interfaces, 127.0.0.1 for localhost only)",
          "public_facing (boolean)"
        ]
      },
      "docker_implications": {
        "docker_mapping": "Typically host_port == container_port for simplicity",
        "example": "Service on port 8000 → docker-compose: '8000:8000'",
        "conflict_prevention": "Port registry ensures no two containers map to same host port"
      }
    },
    {
      "action_id": "SE-02-A05",
      "description": "Create security architecture (CONDITIONAL - required for IT systems with human users)",
      "condition": {
        "check": "framework_id == 'uaf' AND system has human users OR external API access",
        "if_true": "Create security_architecture.json with authentication, authorization, and security controls",
        "if_false": "Skip - internal machine-to-machine systems may have lighter security requirements",
        "applicable_frameworks": ["uaf"],
        "user_detection": "Check if any service has 'user_facing: true' OR 'external_api: true' in service_architecture.json"
      },
      "template": "security_architecture_template.json",
      "location": "specs/machine/security_architecture.json",
      "purpose": "Define comprehensive security architecture UPFRONT - authentication, authorization, API gateway, rate limiting, encryption, audit logging",
      "rationale": "IT systems in modern, interconnected world must prioritize security from the start. Retrofitting security is expensive and risky.",
      "required_sections": [
        "security_posture (classification, user_types, threat_model)",
        "authentication (strategy, session_management, MFA)",
        "authorization (RBAC, permissions, enforcement points)",
        "api_gateway (gateway type, SSL/TLS, CORS, routing)",
        "rate_limiting (strategy, limits, enforcement)",
        "input_validation (XSS, SQL injection prevention)",
        "encryption (in-transit TLS, at-rest AES-256, key management)",
        "audit_logging (events to log, retention, alerting)"
      ],
      "human_user_scenarios": [
        "Web application with end users → REQUIRED",
        "Mobile app with authentication → REQUIRED",
        "Third-party developer API access → REQUIRED",
        "Admin dashboard → REQUIRED",
        "Internal microservices only → OPTIONAL (lighter security acceptable)"
      ],
      "upfront_emphasis": {
        "critical": "Security is NOT an afterthought. Design authentication and authorization flows BEFORE implementing any service.",
        "blocking": "Security architecture must be reviewed and approved before SE-03 validation gate",
        "user_experience_impact": "Poor security UX (complex auth flows, unclear errors) leads to user abandonment and support tickets"
      }
    },
    {
      "action_id": "SE-02-A06",
      "description": "Create deployment architecture (CONDITIONAL - required for IT systems)",
      "condition": {
        "check": "framework_id == 'uaf' AND deployment_characteristics.port_management_applicable == true",
        "if_true": "Create deployment_architecture.json emphasizing ease and simplicity",
        "if_false": "Skip - non-IT systems (biology, ecology) don't have deployment infrastructure",
        "applicable_frameworks": ["uaf"]
      },
      "template": "deployment_architecture_template.json",
      "location": "specs/machine/deployment_architecture.json",
      "purpose": "Design deployment for EASE, SIMPLICITY, and STRAIGHTFORWARD operation. Enable one-command deployment and rapid rollback.",
      "rationale": "Complex deployment processes slow iteration, increase errors, and frustrate developers. Deployment simplicity is a competitive advantage.",
      "required_sections": [
        "deployment_philosophy (one_command_deployment, reproducible, automated_rollback, zero_downtime)",
        "containerization (Docker/Podman, image standards, scanning)",
        "orchestration (docker-compose OR kubernetes - choose simpler option)",
        "ci_cd_pipeline (build, test, deploy stages, automated testing)",
        "environment_management (dev, staging, prod parity)",
        "service_discovery (DNS, health checks, readiness/liveness probes)",
        "monitoring_observability (metrics, logging, tracing, alerting)",
        "backup_disaster_recovery (backup strategy, restore testing, RTO/RPO)"
      ],
      "simplicity_first_principle": {
        "default": "Use Docker Compose unless Kubernetes features absolutely necessary",
        "one_command": "System MUST deploy with single command: 'docker-compose up -d' or 'kubectl apply -f manifests/'",
        "quick_start_time": "Target: New developer can deploy entire system in < 10 minutes from git clone",
        "documentation": "README.md must have step-by-step deployment instructions with expected outputs"
      },
      "upfront_emphasis": {
        "critical": "Deployment complexity is NOT deferred to later. Design for ease of deployment NOW to enable rapid iteration.",
        "blocking": "Deployment architecture must be validated before development begins",
        "developer_experience_impact": "If deployment is painful, developers avoid testing integrated system → integration bugs discovered late"
      }
    },
    {
      "action_id": "SE-02-A07",
      "description": "Create UX and API design architecture (CONDITIONAL - required for IT systems with human users or external APIs)",
      "condition": {
        "check": "framework_id == 'uaf' AND (system has human users OR external API consumers)",
        "if_true": "Create ux_api_design.json with user experience principles and API design standards",
        "if_false": "Skip - internal machine-to-machine systems may not need user-facing design",
        "applicable_frameworks": ["uaf"],
        "user_detection": "Check if any service has 'user_facing: true' OR 'external_api: true' OR 'api_gateway' service exists"
      },
      "template": "ux_api_design_template.json",
      "location": "specs/machine/ux_api_design.json",
      "purpose": "Ensure STRAIGHTFORWARD and POSITIVE user experience. Design intuitive APIs, clear error messages, comprehensive documentation.",
      "rationale": "Poor UX leads to user abandonment, support burden, and negative reputation. API design affects every integration and can't be easily changed.",
      "required_sections": [
        "ux_philosophy (simplicity_first, clear_feedback, error_recovery, accessibility)",
        "api_design_principles (REST/GraphQL, consistency, backwards_compatibility)",
        "rest_api_design (resource modeling, query params, pagination, filtering)",
        "error_handling (user-friendly messages, validation errors, recovery guidance)",
        "api_documentation (OpenAPI spec, interactive docs, getting started guide, code examples)",
        "versioning_strategy (url_path versioning, deprecation policy, migration guide)",
        "performance_ux (response time targets, caching, compression)",
        "authentication_ux (clear auth flow, token management, sandbox environment)"
      ],
      "api_gateway_requirement": {
        "mandatory": "If system has human users OR external APIs, api_gateway service MUST exist",
        "responsibilities": [
          "Single entry point (unified base URL: https://api.example.com)",
          "Authentication enforcement",
          "Rate limiting",
          "Request validation",
          "SSL/TLS termination",
          "CORS handling",
          "Request ID tracking for troubleshooting"
        ],
        "orphaned_service_prevention": "api_gateway MUST be implemented, not just scaffolding. Validate in SE-06 graph analysis."
      },
      "user_experience_targets": {
        "time_to_first_success": "New user completes first successful action in < 5 minutes",
        "api_time_to_first_call": "Developer makes first successful API call in < 5 minutes from reading docs",
        "task_success_rate": "> 95% of users complete common tasks without support",
        "error_recovery": "Errors provide actionable guidance, not just failure messages"
      },
      "upfront_emphasis": {
        "critical": "UX is NOT polish added later. Core user flows and API contracts designed NOW prevent costly refactoring.",
        "blocking": "UX and API design must be reviewed before implementation",
        "modern_world_requirement": "IT systems compete on user experience. Clunky APIs and confusing UX lose users to competitors."
      }
    },
    {
      "action_id": "SE-02-A08",
      "description": "Design operational environment (CONDITIONAL - required for UAF/IT systems going to production)",
      "condition": {
        "check": "framework_id == 'uaf' AND system will be deployed to production",
        "if_true": "Create operational_environment.json defining real-world operational conditions, scalability, resilience, testing strategy",
        "if_false": "Skip - research prototypes or non-IT frameworks don't need operational environment design",
        "applicable_frameworks": ["uaf"]
      },
      "template": "operational_environment_template.json",
      "location": "specs/machine/operational_environment.json",
      "purpose": "Design for REAL operational environment (not benign vacuum) UPFRONT during architecture. Define which tests to run, why, and success criteria. Testing phase executes tests defined here.",
      "rationale": "Systems don't operate in ideal conditions - they face failures, attacks, load spikes, network partitions. NOT considering operational environment upfront causes budget overages and costly program delays.",
      "critical_principle": "Operational environment is an ARCHITECTURAL DECISION, not an operational problem. Testing phase (workflow 04) EXECUTES tests defined here, it does NOT define new tests.",
      "required_sections_10_considerations": [
        {
          "consideration": "1. Service Decomposition & Boundaries",
          "content": "DDD bounded contexts, single responsibility per service, data ownership (dedicated DB per service), inter-service communication (sync REST vs async events)",
          "upfront_decision": "Service boundaries affect scalability, deployment independence, team organization. Can't be easily changed after implementation."
        },
        {
          "consideration": "2. Containerization & Packaging",
          "content": "Docker from day one, multi-stage Dockerfiles, orchestration choice (ECS vs EKS), image scanning, runtime dependencies",
          "upfront_decision": "Containerization strategy determines deployment portability, environment consistency, CI/CD pipeline design."
        },
        {
          "consideration": "3. Infrastructure as Code & Automation",
          "content": "Ansible for deployment automation, Terraform for AWS provisioning, environment separation (dev/staging/prod), dynamic inventories",
          "upfront_decision": "IaC enables reproducible deployments, disaster recovery, environment parity. Manual infrastructure is error-prone."
        },
        {
          "consideration": "4. CI/CD Pipeline Integration",
          "content": "Git workflow, automated testing (unit, integration, security, performance), semantic versioning, secrets injection",
          "upfront_decision": "Pipeline design determines deployment velocity, quality gates, rollback speed. Complex pipelines slow iteration."
        },
        {
          "consideration": "5. Scalability & Resilience",
          "content": "Horizontal scaling, circuit breakers, retries with backoff, timeouts, bulkheads, state management (stateless services, external state storage)",
          "upfront_decision": "Resilience patterns prevent cascading failures. Stateful services limit scalability. Design for 10x growth from start."
        },
        {
          "consideration": "6. Security & Compliance",
          "content": "IAM roles (not credentials), Secrets Manager, VPC design (public/private subnets), security groups, WAF, mTLS, encryption (TLS 1.2+, KMS), compliance (GDPR, HIPAA, PCI-DSS)",
          "upfront_decision": "Security architecture determines compliance eligibility, data residency, audit capabilities. Retrofitting security is expensive."
        },
        {
          "consideration": "7. Monitoring, Logging, Observability",
          "content": "Metrics (Prometheus /metrics), structured JSON logging, correlation IDs, distributed tracing, alerting (critical vs warning), dashboards, performance baselines",
          "upfront_decision": "Observability strategy determines debuggability, incident response time, proactive issue detection. No observability = blind operations."
        },
        {
          "consideration": "8. Service Discovery & Networking",
          "content": "Discovery mechanism (Cloud Map, Consul, K8s DNS), API Gateway (single entry point), latency optimization (same VPC/AZ), CDN, connection pooling",
          "upfront_decision": "Service discovery enables dynamic scaling. Hardcoded IPs break auto-scaling. API Gateway enforces consistent auth/rate limiting."
        },
        {
          "consideration": "9. Cost Management & Optimization",
          "content": "Right-sizing instances, spot instances for non-critical, reserved instances for baseline, auto-scaling to zero, serverless options (Lambda, Fargate), tagging for cost allocation",
          "upfront_decision": "Cost optimization designed in prevents runaway cloud costs. Post-deployment optimization is reactive and limited."
        },
        {
          "consideration": "10. Testing & Rollback Strategies",
          "content": "Define which tests to run (unit, integration, performance, security, chaos, operational), canary deployments, feature flags, backup/DR, rollback procedures",
          "upfront_decision": "Testing strategy defined NOW determines quality gates, operational readiness. Testing phase EXECUTES these tests, doesn't invent them."
        }
      ],
      "operational_environment_conditions": {
        "real_world_not_vacuum": "Systems face network failures, resource exhaustion, cascading failures, traffic spikes, security attacks, data corruption, third-party outages, configuration drift",
        "design_response": "Circuit breakers, timeouts, retries, bulkheads, auto-scaling, rate limiting, WAF, input validation, data validation, fallbacks, IaC",
        "test_plan": "Chaos engineering, load testing, spike testing, fault injection, penetration testing, configuration drift detection"
      },
      "testing_phase_relationship": {
        "systems_engineering_phase": "Define operational environment, decide which tests needed, design for real-world conditions, establish success criteria",
        "testing_phase": "Execute tests planned during SE phase, validate system survives operational conditions, measure against baselines",
        "critical_distinction": "Testing phase does NOT define new tests - those are architectural decisions made NOW. Testing phase validates architecture works."
      },
      "upfront_emphasis": {
        "critical": "Operational environment is NOT deferred to testing phase. Real operational conditions (failures, attacks, load) designed for NOW.",
        "blocking": "Operational environment design must be validated before SE-03 gate",
        "cost_impact": "NOT considering operational environment upfront causes budget overages and costly program delays (10-100x more expensive to retrofit)",
        "production_readiness": "Focus on scalability, reliability, security, maintainability in production from day one"
      }
    },

    {
      "action_id": "SE-02-A09",
      "action_name": "Define Operational Testing Objectives",
      "description": "Define operational testing objectives and testability requirements for each service",
      "when": "During service architecture specification (SE-02), after operational environment design (A08)",
      "purpose": "Define how each service will be tested operationally, ensuring architecture is testable by design",
      "template": "operational_testing_objectives_template.json",
      "creates": "specs/machine/service_arch/{service}/operational_testing_objectives.json",
      "new_in_version": "Reflow v3.6.0 - Early Testing Integration feature",

      "applicability": {
        "applies_to": "All frameworks",
        "note": "Testing strategy is universal - UAF services, biological systems, social networks all need testability"
      },

      "sections": {
        "testability_requirements": {
          "description": "Architectural features that enable testing",
          "includes": [
            "Health endpoints (/health, /ready) for services",
            "Observability hooks (metrics, logs, traces) for runtime inspection",
            "Configuration validation endpoints for deployment verification",
            "Test interfaces (stub dependencies, mock data sources)",
            "Deterministic behavior (avoid randomness that prevents reproducible tests)",
            "Graceful degradation patterns (predictable failure modes)"
          ],
          "examples": {
            "uaf_service": "REST /health endpoint, Prometheus /metrics, test database mode",
            "biological_model": "Observable state variables, simulation reproducibility via seed",
            "social_network": "Graph state export, query API for validation"
          }
        },

        "deployment_test_scenarios": {
          "description": "Tests to validate deployment configuration, not business logic",
          "scenarios": [
            {
              "scenario": "Startup validation",
              "test": "Service starts successfully with production-like configuration",
              "success_criteria": "Container starts, health endpoint responds 200 OK within 30s"
            },
            {
              "scenario": "Database connection",
              "test": "Service connects to database with correct permissions",
              "success_criteria": "Connection established, migrations run successfully as service user"
            },
            {
              "scenario": "Dependency handling",
              "test": "Service handles missing/failed dependencies gracefully",
              "success_criteria": "Circuit breaker trips, service returns 503 with clear error message"
            },
            {
              "scenario": "Configuration validation",
              "test": "Service validates configuration at startup",
              "success_criteria": "Invalid config detected, service fails fast with actionable error"
            },
            {
              "scenario": "Resource limits",
              "test": "Service operates within memory/CPU constraints",
              "success_criteria": "Container stays within limits (e.g., <512MB RAM) under load"
            }
          ]
        },

        "operational_acceptance_criteria": {
          "description": "Criteria for service to be considered deployment-ready",
          "criteria": [
            {
              "criterion": "Startup time",
              "target": "< 30 seconds from container start to health check passing",
              "rationale": "Fast startup enables rapid scaling and recovery"
            },
            {
              "criterion": "Health check response",
              "target": "< 100ms for /health endpoint",
              "rationale": "Orchestrators need fast health checks for rapid failure detection"
            },
            {
              "criterion": "Graceful shutdown",
              "target": "Completes in-flight requests within 30s on SIGTERM",
              "rationale": "Zero-downtime deployments require graceful draining"
            },
            {
              "criterion": "Crash recovery",
              "target": "Automatic restart and recovery without manual intervention",
              "rationale": "Production resilience requires self-healing"
            }
          ]
        },

        "smoke_test_requirements": {
          "description": "Fast tests (<30s) to validate basic functionality after deployment",
          "tests": [
            {
              "test": "CRUD operations",
              "what": "Create, read, update, delete primary entities",
              "time": "< 5 seconds",
              "purpose": "Verify core business logic works"
            },
            {
              "test": "Authentication",
              "what": "Valid token accepted, invalid token rejected",
              "time": "< 2 seconds",
              "purpose": "Verify security controls work"
            },
            {
              "test": "Database migrations",
              "what": "Schema matches expected version",
              "time": "< 1 second (query)",
              "purpose": "Verify database setup correct"
            },
            {
              "test": "Inter-service communication",
              "what": "Service can call dependencies and handle responses",
              "time": "< 5 seconds",
              "purpose": "Verify integration points work"
            }
          ]
        }
      },

      "execution_steps": [
        "1. For EACH service in architecture, create operational_testing_objectives.json",
        "2. Load template from templates/operational_testing_objectives_template.json",
        "3. Define testability requirements (health endpoints, observability, test interfaces)",
        "4. Define 3-5 deployment test scenarios specific to service complexity",
        "5. Set operational acceptance criteria with measurable targets",
        "6. Define smoke tests that complete in < 30 seconds total",
        "7. Customize based on service risk level (from SE-02-A10 risk assessment)",
        "8. Save to specs/machine/service_arch/{service}/operational_testing_objectives.json"
      ],

      "validation": [
        "All services have operational_testing_objectives.json",
        "Testability requirements include health endpoints and observability",
        "Deployment scenarios cover startup, database, dependencies, config, resources",
        "Acceptance criteria have measurable targets (time, response codes)",
        "Smoke tests defined with time limits"
      ],

      "llm_agent_instructions": [
        "For EACH service, create operational_testing_objectives.json using template",
        "Customize testability requirements based on service complexity",
        "High-risk services (from A10 risk assessment) need more comprehensive testing objectives",
        "Deployment test scenarios should validate infrastructure, not business logic",
        "Smoke tests must be fast (< 30s total) - they run after every deployment",
        "Operational acceptance criteria must be measurable (not subjective)",
        "Connect to service_architecture.json: testability requirements become implementation requirements",
        "These objectives will be used by D-06.5 (pre-deployment validation) and TO-05 (operational testing)"
      ],

      "impact": "SE phase now produces testable architecture with clear testing objectives, not just functional specifications. Prevents 'toss it over the fence' problem by defining testing requirements during architecture design."
    },

    {
      "action_id": "SE-02-A10",
      "action_name": "Service Risk Assessment",
      "description": "Perform risk assessment for each service to guide testing thoroughness",
      "when": "During service architecture specification (SE-02), after defining operational testing objectives (A09)",
      "purpose": "Identify high-risk services requiring more thorough testing (chaos tests, load tests, failover tests)",
      "template": "service_risk_assessment_template.json",
      "creates": "specs/machine/service_arch/{service}/risk_assessment.json",
      "new_in_version": "Reflow v3.6.0 - Early Testing Integration feature",

      "applicability": {
        "applies_to": "All frameworks",
        "note": "Risk assessment is universal - applies to UAF services, biological models, social simulations, ecological systems"
      },

      "risk_categories": {
        "deployment_risk": {
          "description": "Likelihood of deployment failures",
          "factors": [
            "Complex dependencies (database, message queue, external APIs)",
            "Stateful migrations (schema changes, data transformations)",
            "Resource-intensive (high memory, CPU, or disk usage)",
            "Platform-specific (native dependencies, OS-level requirements)"
          ],
          "severity_levels": {
            "low": "Stateless service, minimal dependencies (e.g., utility APIs)",
            "medium": "Database-backed service with migrations",
            "high": "Distributed state, complex migrations, external integrations"
          }
        },

        "integration_risk": {
          "description": "Likelihood of integration failures",
          "factors": [
            "Tight coupling to other services (synchronous dependencies)",
            "Complex data flows (multi-hop, transformations)",
            "Protocol mismatches (REST vs gRPC vs messaging)",
            "External system dependencies (third-party APIs, legacy systems)"
          ],
          "severity_levels": {
            "low": "Standalone service, no external dependencies",
            "medium": "Calls 1-2 internal services asynchronously",
            "high": "Synchronous dependencies on 3+ services or external systems"
          }
        },

        "operational_risk": {
          "description": "Impact of service failure on system",
          "factors": [
            "On critical path (user-facing, revenue-generating)",
            "High traffic volume (>1000 req/sec)",
            "Data integrity critical (financial, health, personal data)",
            "No redundancy or failover"
          ],
          "severity_levels": {
            "low": "Non-critical, background job, batch processing",
            "medium": "Important feature, has degraded mode or redundancy",
            "high": "Critical path, high traffic, single point of failure"
          }
        }
      },

      "risk_matrix": {
        "description": "Overall risk score determines testing thoroughness",
        "calculation": "Average of deployment_risk, integration_risk, operational_risk (1-3 scale: 1=low, 2=medium, 3=high)",
        "risk_levels": {
          "low_risk": {
            "score_range": "1.0 - 1.5",
            "testing_strategy": "Standard testing (unit, integration, smoke tests)",
            "examples": "Logging service, metrics collector, static content API",
            "testing_requirements": "80% unit test coverage, integration tests for key scenarios, smoke tests"
          },
          "medium_risk": {
            "score_range": "1.6 - 2.5",
            "testing_strategy": "Standard + load testing + contract testing",
            "examples": "Authentication service, notification service, search API",
            "testing_requirements": "80% coverage, integration tests, contract tests, load tests (2x expected traffic)"
          },
          "high_risk": {
            "score_range": "2.6 - 3.0",
            "testing_strategy": "Standard + load + chaos + failover + security pentesting",
            "examples": "Payment service, user data service, API gateway, database cluster",
            "testing_requirements": "85% coverage, comprehensive integration/contract tests, load tests (5x traffic), chaos tests, failover tests, security pentesting"
          }
        }
      },

      "execution_steps": [
        "1. For EACH service, assess three risk categories: deployment, integration, operational",
        "2. For each category, review factors and assign severity level: 1=low, 2=medium, 3=high",
        "3. Calculate overall risk score: (deployment_risk + integration_risk + operational_risk) / 3",
        "4. Classify service: low (1.0-1.5), medium (1.6-2.5), or high (2.6-3.0) risk",
        "5. Document rationale for each risk assessment (why this severity level?)",
        "6. Map risk level to testing strategy per risk_matrix above",
        "7. High-risk services (score >= 2.6) MUST have chaos, load, failover tests in TO-05",
        "8. Save to specs/machine/service_arch/{service}/risk_assessment.json"
      ],

      "validation": [
        "All services have risk_assessment.json",
        "Each risk category has severity level (1, 2, or 3) with rationale",
        "Overall risk score calculated correctly",
        "Testing strategy matches risk level per risk_matrix",
        "High-risk services (>= 2.6) flagged for comprehensive operational testing"
      ],

      "llm_agent_instructions": [
        "For EACH service, perform risk assessment using three categories",
        "Be honest about risk - underestimating risk leads to insufficient testing and production failures",
        "Common high-risk indicators: payment processing, user authentication, data storage, API gateway, single point of failure",
        "Common low-risk indicators: logging, metrics, static content, internal utilities",
        "Document rationale - future maintainers need to understand WHY service is high/low risk",
        "Risk assessment feeds into: (1) operational testing objectives (A09), (2) system test strategy (SE-06-A06), (3) operational testing (TO-05)",
        "High-risk services require prototyping (D-01-A06) and prove-it-works gates (D-02-A99 through D-05-A99)",
        "Use risk scores during development to prioritize testing effort on high-risk services"
      ],

      "impact": "Testing strategy becomes risk-based, focusing effort on high-risk services instead of uniform testing for all. Prevents over-testing low-risk services and under-testing high-risk services.",

      "relationship_to_other_actions": {
        "informs_SE-06-A06": "System test strategy (SE-06-A06) uses risk assessments to determine which services need chaos/load/failover tests",
        "informs_D-01-A06": "High-risk services (>= 2.6) should use prototyping (D-01-A06) to validate assumptions early",
        "informs_D-0X-A99": "High-risk services require stricter prove-it-works validation at each development step",
        "informs_TO-05": "High-risk services get comprehensive operational testing (chaos, load, failover); low-risk get standard tests"
      }
    }
  ],

  "tools_used": [
    "validate_port_registry.py"
  ],

  "templates_used": [
    "service_architecture_template.json",
    "component_specification_complete_template.json",
    "interface_registry_enhanced_template.json",
    "port_registry_template.json",
    "security_architecture_template.json",
    "deployment_architecture_template.json",
    "ux_api_design_template.json",
    "operational_environment_template.json",
    "operational_testing_objectives_template.json",
    "service_risk_assessment_template.json"
  ],

  "outputs": [
    "specs/machine/service_arch/{service_name}/service_architecture_v1.json (per service) - with port assignments",
    "specs/machine/interface_registry.json",
    "specs/machine/port_registry.json",
    "specs/machine/security_architecture.json (if UAF with human users)",
    "specs/machine/deployment_architecture.json (if UAF/IT system)",
    "specs/machine/ux_api_design.json (if UAF with human users/external APIs)",
    "specs/machine/operational_environment.json (if UAF/IT system going to production)",
    "specs/machine/service_arch/{service_name}/operational_testing_objectives.json (per service) - NEW in v3.6.0",
    "specs/machine/service_arch/{service_name}/risk_assessment.json (per service) - NEW in v3.6.0"
  ],

  "llm_agent_guidance": {
    "critical_reminders": [
      "Create VERSIONED architecture files (v1.0.0-{date}.json) with symlinks",
      "CONDITIONAL actions: Check framework_id and user_facing flags before executing A04-A08",
      "Port registry (A04): Only for IT systems (framework_id == 'uaf')",
      "Security (A05), Deployment (A06), UX (A07), Operational (A08): Only for UAF with human users or production systems",
      "Edge weights (A02B): Required for Decision Flow and Ecological frameworks if doing flow analysis",
      "Never skip conditional checks - executing wrong actions wastes time and creates incorrect artifacts"
    ],
    "common_mistakes": [
      "Creating port_registry.json for biological systems (doesn't apply)",
      "Skipping security_architecture.json for user-facing web apps (required!)",
      "Not creating versioned files with symlinks",
      "Forgetting to plan edge weights for Decision Flow framework → flow analysis fails later"
    ]
  }
}
