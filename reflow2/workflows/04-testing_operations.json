{
  "workflow_metadata": {
    "workflow_id": "04-testing_operations",
    "name": "Testing & Operations Workflow",
    "version": "1.0.0",
    "description": "Test, validate, deploy, and release the system",
    "created_from": "decision_flow.json v2.5.0 - extracted Dev-06, Dev-07, Dev-08",
    "last_updated": "2025-10-24",
    "purpose": "Ensure system is production-ready through comprehensive testing and operational validation"
  },
  "prerequisites": {
    "required_workflows": ["00-setup", "01-systems_engineering", "02-artifacts_visualization", "03-development"],
    "required_files": [
      "services/{service_name}/src/ (complete implementation)",
      "services/{service_name}/tests/ (test suite with >= 80% coverage)",
      "services/build_ready_index.json"
    ],
    "required_conditions": [
      "All services implemented",
      "All tests passing",
      "Test coverage >= 80%",
      "Observability instrumentation complete"
    ]
  },
  "entry_points": {
    "from_development": {
      "id": "from_development",
      "description": "Standard entry after completing development workflow",
      "first_step": "TO-01"
    }
  },
  "context_management": {
    "description": "Prevent context drift and token exhaustion during workflow execution",
    "template_reference": "See templates/context_management_template.json for complete details",
    "rag_enhanced_mode": {
      "description": "RECOMMENDED - Use RAG for automatic context injection and degradation detection",
      "setup": "Initialize in S-03-A05 (Setup workflow)",
      "benefits": "Automatic context refresh, degradation detection, token-efficient retrieval",
      "usage": "python3 {reflow_root}/tools/rag_agent_wrapper.py {system_root} wrap --query 'your query' --strategy on_step_start",
      "fallback": "If RAG not set up, use manual operations counter and refresh sequence below"
    },
    "operations_counter": {
      "threshold": 5,
      "tracking_location": "context/working_memory.json (operations_since_refresh field)",
      "rule": "Increment after each real operation (test execution, pipeline setup, deployment)",
      "refresh_trigger": "When >= 5, execute refresh sequence immediately"
    },
    "degradation_signals_watch_for": [
      "Running tests against wrong environment",
      "Deploying to wrong target",
      "Skipping mandatory quality gates",
      "Working in wrong directory (pwd != system_root)",
      "Forgetting which deployment stage (DTE/OTE/Prod)"
    ],
    "refresh_sequence_summary": [
      "1. PAUSE - Stop all operations",
      "2. VERIFY PWD - Confirm in correct directory",
      "3. SAVE STATE - Update working_memory.json and step_progress_tracker.json",
      "4. RELOAD - Read workflow file, deployment configs, test plans",
      "5. READ - current_focus.md and step_progress_tracker.json",
      "6. CONFIRM - State system name, deployment stage, next action",
      "7. RESET - Set operations_since_refresh = 0",
      "8. RESUME - Continue with confirmed action"
    ],
    "pre_operation_checklist": [
      "Verify pwd equals system_root",
      "Read current_focus.md",
      "Read step_progress_tracker.json",
      "Verify deploying to correct environment",
      "Check operations_since_refresh <= 4",
      "Verify not skipping quality gates"
    ]
  },
  "self_improvement": {
    "description": "Continuous workflow improvement through observation and metrics",
    "template_reference": "See templates/self_improvement_template.json for complete details",
    "during_execution": {
      "observe": ["Test execution time", "Deployment speed", "Test flakiness", "Pipeline reliability", "Operational readiness"],
      "document": "Log observations to context/process_log.md with timestamps",
      "track_metrics": "Update context/workflow_metrics.json after each step"
    },
    "after_completion": {
      "retrospective_file": "context/workflow_retrospective_04-testing_operations_{date}.md",
      "key_questions": [
        "What worked well?",
        "What tests were flaky or slow?",
        "What deployment issues occurred?",
        "What took longer than expected?",
        "How could testing/deployment be improved?"
      ],
      "improvement_submission": "Add entries to WORKFLOW_IMPROVEMENTS_BACKLOG.md"
    }
  },
  "workflow_steps": [
    {
      "step_id": "TO-01",
      "name": "Development Test Execution (DTE)",
      "description": "Comprehensive testing in development environment",
      "phase": "testing",
      "step_file": "workflow_steps/testing_operations/TO-01-DevelopmentTesting.json",
      "maps_from": "Parts of Dev-05, Dev-06: Development testing",
      "actions": [
        {
          "action_id": "TO-01-A01",
          "description": "Run complete unit test suite",
          "purpose": "Verify all units of code function correctly",
          "command_pattern": "pytest services/{service_name}/tests/unit/ (or language-specific)",
          "success_criteria": "All unit tests pass"
        },
        {
          "action_id": "TO-01-A02",
          "description": "Run integration tests",
          "purpose": "Verify components work together correctly",
          "command_pattern": "pytest services/{service_name}/tests/integration/",
          "success_criteria": "All integration tests pass"
        },
        {
          "action_id": "TO-01-A03",
          "description": "Run contract tests",
          "tool": "verify_component_contract.py",
          "command_pattern": "python3 {reflow_root}/tools/verify_component_contract.py {system_root} --all-services",
          "purpose": "Verify all services comply with ICDs",
          "success_criteria": "All contract verifications pass"
        },
        {
          "action_id": "TO-01-A04",
          "description": "Run security tests",
          "test_types": [
            "Authentication tests",
            "Authorization tests",
            "Input validation tests",
            "SQL injection prevention tests",
            "XSS prevention tests"
          ],
          "purpose": "Verify security controls work correctly"
        },
        {
          "action_id": "TO-01-A05",
          "description": "Generate test coverage report",
          "tools": ["coverage.py", "istanbul", "JaCoCo"],
          "gate_enforcement": "Block if coverage < 80%",
          "output": "Test coverage report"
        },
        {
          "action_id": "TO-01-A06",
          "description": "Create DTE artifacts",
          "template": "dte_artifacts_template.json",
          "location": "specs/machine/dte_artifacts.json",
          "includes": [
            "Test results summary",
            "Coverage metrics",
            "Failed test details (if any)",
            "Test execution timestamp"
          ]
        }
      ],
      "tools_used": ["verify_component_contract.py", "Test frameworks (language-specific)"],
      "templates_used": ["dte_artifacts_template.json"],
      "outputs": [
        "Test results",
        "Coverage reports",
        "specs/machine/dte_artifacts.json"
      ],
      "gates": [
        {
          "gate_id": "G-TO-01",
          "name": "Development Testing Gate",
          "checks": [
            "All unit tests passing",
            "All integration tests passing",
            "All contract tests passing",
            "All security tests passing",
            "Test coverage >= 80%"
          ],
          "blocking": true
        }
      ],
      "next_step": "TO-02"
    },
    {
      "step_id": "TO-02",
      "name": "CI/CD Setup & Automation",
      "description": "Set up continuous integration and deployment pipelines",
      "phase": "automation",
      "step_file": "workflow_steps/testing_operations/TO-02-CICDSetup.json",
      "maps_from": "Dev-06: CI/CD & Deployment",
      "actions": [
        {
          "action_id": "TO-02-A01",
          "description": "Create CI pipeline configuration",
          "platforms": ["GitHub Actions", "GitLab CI", "Jenkins", "CircleCI", "Azure DevOps"],
          "location_pattern": ".github/workflows/ci.yml or .gitlab-ci.yml or Jenkinsfile",
          "pipeline_stages": [
            "Build (compile, package)",
            "Test (unit, integration)",
            "Lint & format check",
            "Security scan",
            "Coverage report"
          ]
        },
        {
          "action_id": "TO-02-A02",
          "description": "Create CD pipeline configuration",
          "pipeline_stages": [
            "Build container images",
            "Push to container registry",
            "Deploy to staging",
            "Run smoke tests",
            "Deploy to production (manual approval)"
          ]
        },
        {
          "action_id": "TO-02-A03",
          "description": "Create Dockerfiles for each service",
          "location_pattern": "services/{service_name}/Dockerfile",
          "best_practices": [
            "Multi-stage builds",
            "Minimal base images",
            "Non-root user",
            "Health check instruction"
          ]
        },
        {
          "action_id": "TO-02-A04",
          "description": "Create container image build scripts",
          "purpose": "Automate container image creation",
          "versioning": "Use semantic versioning for images"
        },
        {
          "action_id": "TO-02-A05",
          "description": "Configure automated quality gates",
          "gates": [
            "Test coverage threshold (80%)",
            "Linting passes",
            "Security vulnerabilities threshold",
            "Code complexity threshold"
          ]
        },
        {
          "action_id": "TO-02-A06",
          "description": "Set up deployment automation",
          "methods": [
            "Kubernetes manifests",
            "Helm charts",
            "Terraform/CloudFormation",
            "Docker Compose (staging)"
          ]
        }
      ],
      "tools_used": ["Docker", "CI/CD platform", "Container registry"],
      "outputs": [
        "CI/CD pipeline configurations",
        "services/{service_name}/Dockerfile (per service)",
        "Deployment manifests",
        "Container images"
      ],
      "gates": [],
      "next_step": "TO-03"
    },
    {
      "step_id": "TO-03",
      "name": "Deployment Validation",
      "description": "Validate deployment artifacts and local deployment",
      "phase": "deployment",
      "step_file": "workflow_steps/testing_operations/TO-03-DeploymentValidation.json",
      "maps_from": "Dev-06: Deployment validation",
      "actions": [
        {
          "action_id": "TO-03-A01",
          "description": "Create Docker Compose file for local deployment",
          "location": "docker-compose.yml or services/docker-compose.yml",
          "purpose": "Enable local multi-service deployment",
          "includes": [
            "All services",
            "Databases",
            "Message queues",
            "Networking configuration",
            "Volume mounts"
          ]
        },
        {
          "action_id": "TO-03-A02",
          "description": "Validate Docker Compose deployment",
          "commands": [
            "docker-compose up -d",
            "docker-compose ps (verify all healthy)",
            "docker-compose logs (check for errors)",
            "docker-compose down"
          ],
          "purpose": "Ensure all services start and communicate correctly",
          "gate_enforcement": "Block if Docker Compose deployment fails"
        },
        {
          "action_id": "TO-03-A03",
          "description": "Run smoke tests on Docker Compose deployment",
          "test_types": [
            "Health check endpoints (/health, /ready)",
            "Basic API functionality",
            "Service-to-service communication",
            "Database connectivity"
          ],
          "purpose": "Verify basic functionality in deployed environment"
        },
        {
          "action_id": "TO-03-A04",
          "description": "Validate deployment manifests",
          "manifests": ["Kubernetes YAML", "Helm charts", "Terraform"],
          "validation": [
            "Syntax validation",
            "Resource limits defined",
            "Health checks configured",
            "Environment variables set"
          ]
        },
        {
          "action_id": "TO-03-A05",
          "description": "Test deployment to staging environment",
          "purpose": "Validate deployment process in real environment",
          "success_criteria": "All services deploy and pass health checks"
        }
      ],
      "tools_used": ["Docker", "Docker Compose", "kubectl (if using Kubernetes)"],
      "outputs": [
        "docker-compose.yml",
        "Validated deployment manifests",
        "Smoke test results"
      ],
      "gates": [
        {
          "gate_id": "G-TO-03",
          "name": "Deployment Validation Gate",
          "checks": [
            "Docker Compose deployment successful",
            "All services healthy in Docker Compose",
            "Smoke tests passing",
            "Deployment manifests validated"
          ],
          "blocking": true
        }
      ],
      "next_step": "TO-04"
    },
    {
      "step_id": "TO-04",
      "name": "Operational Readiness",
      "description": "Prepare for production operations with runbooks and procedures",
      "phase": "operations",
      "step_file": "workflow_steps/testing_operations/TO-04-OperationalReadiness.json",
      "maps_from": "Dev-07: Operational Readiness & Runbooks",
      "actions": [
        {
          "action_id": "TO-04-A01",
          "description": "Create operational runbooks",
          "location": "docs/runbooks/",
          "runbooks": [
            "Deployment procedure",
            "Rollback procedure",
            "Incident response",
            "Troubleshooting guide",
            "Scaling procedure",
            "Backup and recovery"
          ]
        },
        {
          "action_id": "TO-04-A02",
          "description": "Document monitoring and alerting",
          "includes": [
            "Key metrics to monitor",
            "Alert thresholds",
            "Alert routing (who gets notified)",
            "Dashboard links"
          ],
          "location": "docs/runbooks/MONITORING.md"
        },
        {
          "action_id": "TO-04-A03",
          "description": "Create operational checklists",
          "checklists": [
            "Pre-deployment checklist",
            "Post-deployment verification",
            "Incident response checklist",
            "Rollback checklist"
          ],
          "location": "docs/runbooks/CHECKLISTS.md"
        },
        {
          "action_id": "TO-04-A04",
          "description": "Configure monitoring and alerting",
          "monitoring": [
            "Application metrics (Prometheus/Grafana)",
            "Infrastructure metrics (CPU, memory, disk)",
            "Log aggregation (ELK, Splunk, CloudWatch)",
            "Distributed tracing (Jaeger, Zipkin)"
          ],
          "alerts": [
            "Service down alerts",
            "High error rate alerts",
            "Performance degradation alerts",
            "Resource exhaustion alerts"
          ]
        },
        {
          "action_id": "TO-04-A05",
          "description": "Define SLIs, SLOs, and SLAs",
          "definitions": [
            "SLI (Service Level Indicators): What you measure",
            "SLO (Service Level Objectives): Target values",
            "SLA (Service Level Agreements): Commitments to users"
          ],
          "examples": [
            "Availability SLO: 99.9% uptime",
            "Latency SLO: p95 < 200ms",
            "Error rate SLO: < 0.1%"
          ],
          "location": "docs/SLO.md"
        },
        {
          "action_id": "TO-04-A06",
          "description": "Conduct operational readiness review",
          "review_areas": [
            "Runbooks complete and tested",
            "Monitoring and alerting configured",
            "On-call rotation established",
            "Incident response process defined",
            "Disaster recovery plan documented"
          ]
        }
      ],
      "tools_used": ["Monitoring platforms", "Alerting systems"],
      "outputs": [
        "docs/runbooks/ (multiple runbook documents)",
        "docs/SLO.md",
        "Monitoring dashboards",
        "Alert configurations"
      ],
      "gates": [
        {
          "gate_id": "G-TO-04",
          "name": "Operational Readiness Gate",
          "checks": [
            "All critical runbooks created",
            "Monitoring configured",
            "Alerting configured",
            "SLOs defined",
            "Operational readiness review complete"
          ],
          "blocking": false
        }
      ],
      "next_step": "TO-05"
    },
    {
      "step_id": "TO-05",
      "name": "Operational Testing & Release",
      "description": "End-to-end testing and production release certification",
      "phase": "release",
      "step_file": "workflow_steps/testing_operations/TO-05-OperationalTesting.json",
      "maps_from": "Dev-08: Operational Validation & Release",
      "actions": [
        {
          "action_id": "TO-05-A01",
          "description": "Run end-to-end (E2E) tests in staging",
          "purpose": "Validate complete user journeys in realistic environment",
          "test_scenarios": "Based on docs/USER_SCENARIOS.md",
          "tools": ["Selenium", "Cypress", "Playwright", "Postman"],
          "success_criteria": "All E2E tests pass"
        },
        {
          "action_id": "TO-05-A02",
          "description": "Conduct user acceptance testing (UAT)",
          "purpose": "Validate system meets user requirements",
          "participants": "Product owner, key stakeholders",
          "based_on": ["docs/USER_SCENARIOS.md", "docs/SUCCESS_CRITERIA.md"],
          "success_criteria": "UAT sign-off received"
        },
        {
          "action_id": "TO-05-A03",
          "description": "Run performance testing",
          "test_types": [
            "Load testing (expected load)",
            "Stress testing (breaking point)",
            "Soak testing (sustained load)",
            "Spike testing (sudden load changes)"
          ],
          "tools": ["JMeter", "Gatling", "k6", "Locust"],
          "success_criteria": "Performance meets SLOs"
        },
        {
          "action_id": "TO-05-A04",
          "description": "Conduct security testing",
          "test_types": [
            "Vulnerability scanning",
            "Penetration testing",
            "Dependency scanning",
            "Container image scanning"
          ],
          "tools": ["OWASP ZAP", "Burp Suite", "Snyk", "Trivy"],
          "success_criteria": "No critical vulnerabilities"
        },
        {
          "action_id": "TO-05-A05",
          "description": "Run disaster recovery drills",
          "scenarios": [
            "Database failure and recovery",
            "Service failure and restart",
            "Complete system failure and recovery",
            "Data corruption and restore from backup"
          ],
          "purpose": "Validate backup and recovery procedures"
        },
        {
          "action_id": "TO-05-A06",
          "description": "Create OTE artifacts",
          "template": "ote_artifacts_template.json",
          "location": "specs/machine/ote_artifacts.json",
          "includes": [
            "E2E test results",
            "UAT results",
            "Performance test results",
            "Security test results",
            "DR drill results"
          ]
        },
        {
          "action_id": "TO-05-A07",
          "description": "Release certification decision",
          "decision_point": "Go/No-Go for production release",
          "criteria": [
            "All tests passing",
            "Performance meets SLOs",
            "No critical security vulnerabilities",
            "UAT approved",
            "Operational readiness confirmed"
          ],
          "outputs": "Release certification report"
        },
        {
          "action_id": "TO-05-A08",
          "description": "Deploy to production (if certified)",
          "deployment_strategy": ["Blue-green deployment", "Canary deployment", "Rolling deployment"],
          "post_deployment": [
            "Verify health checks",
            "Monitor metrics",
            "Validate smoke tests",
            "Monitor alerts"
          ]
        }
      ],
      "tools_used": [
        "E2E testing frameworks",
        "Performance testing tools",
        "Security testing tools"
      ],
      "templates_used": ["ote_artifacts_template.json"],
      "outputs": [
        "E2E test results",
        "Performance test results",
        "Security test results",
        "specs/machine/ote_artifacts.json",
        "Release certification report",
        "Production deployment (if approved)"
      ],
      "gates": [
        {
          "gate_id": "G-TO-05",
          "name": "Release Certification Gate",
          "checks": [
            "All E2E tests passing",
            "UAT approved",
            "Performance tests meet SLOs",
            "No critical security vulnerabilities",
            "Disaster recovery validated",
            "Release certification approved"
          ],
          "blocking": true,
          "note": "This is the final gate before production release"
        }
      ],
      "next_step": "TO-06"
    },
    {
      "step_id": "TO-06",
      "name": "As-Fielded Architecture Capture",
      "description": "Generate as-fielded architecture from deployed system and compare to as-designed",
      "phase": "validation",
      "step_file": "workflow_steps/testing_operations/TO-06-AsFieldedArchitecture.json",
      "actions": [
        {
          "action_id": "TO-06-A01",
          "description": "Generate as-fielded architecture graph",
          "tool": "generate_as_fielded_architecture.py",
          "command_pattern": "python3 {reflow_root}/tools/generate_as_fielded_architecture.py --system-root {system_root} --output specs/machine/graphs/system_of_systems_graph_as_fielded.json --compare-to specs/machine/graphs/system_of_systems_graph.json --environment {environment}",
          "purpose": "Capture actual deployed system architecture from runtime inspection",
          "method": "Docker runtime inspection + docker-compose analysis",
          "detects": [
            "Running containers and their status",
            "Actual port mappings",
            "Health endpoint status",
            "Network topology",
            "Service dependencies (from docker-compose)",
            "Resource usage"
          ],
          "environment_values": ["dev", "staging", "production"],
          "outputs": [
            "specs/machine/graphs/system_of_systems_graph_as_fielded.json"
          ]
        },
        {
          "action_id": "TO-06-A02",
          "description": "Compare as-fielded to as-designed architecture",
          "tool": "compare_architectures.py",
          "command_pattern": "python3 {reflow_root}/tools/compare_architectures.py --from specs/machine/graphs/system_of_systems_graph.json --to specs/machine/graphs/system_of_systems_graph_as_fielded.json --output specs/machine/graphs/architecture_delta_designed_to_fielded_{date}.json",
          "purpose": "Identify architectural deviations from design in deployed system",
          "note": "This runs automatically as part of TO-06-A01 (--compare-to flag)",
          "analyzes": [
            "Services not running (should be running)",
            "Unexpected services (not in design)",
            "Port conflicts or changes",
            "Network topology differences",
            "Health check failures",
            "Similarity score (Jaccard similarity)",
            "Breaking vs non-breaking changes"
          ],
          "outputs": [
            "specs/machine/graphs/architecture_delta_designed_to_fielded_{date}.json"
          ]
        },
        {
          "action_id": "TO-06-A03",
          "description": "Compare as-fielded to as-built architecture",
          "tool": "compare_architectures.py",
          "command_pattern": "python3 {reflow_root}/tools/compare_architectures.py --from specs/machine/graphs/system_of_systems_graph_as_built.json --to specs/machine/graphs/system_of_systems_graph_as_fielded.json --output specs/machine/graphs/architecture_delta_built_to_fielded_{date}.json",
          "purpose": "Identify operational changes from implementation to deployment",
          "optional": "Only if as-built graph exists",
          "analyzes": [
            "Deployment-specific changes (ports, environment vars)",
            "Services scaled or removed for operations",
            "Configuration drift"
          ],
          "outputs": [
            "specs/machine/graphs/architecture_delta_built_to_fielded_{date}.json"
          ]
        },
        {
          "action_id": "TO-06-A04",
          "description": "Review delta reports and document operational rationale",
          "purpose": "Understand why deployed system differs from design and implementation",
          "process": [
            "Read architecture_delta_designed_to_fielded_{date}.json",
            "Read architecture_delta_built_to_fielded_{date}.json (if exists)",
            "Review breaking_changes and non_breaking_changes",
            "For each significant change, document operational rationale",
            "Decide: update design OR fix deployment OR accept drift"
          ],
          "decision_criteria": {
            "update_design_if": [
              "Operational constraints not known during design",
              "Production environment requires different architecture",
              "Scalability requirements changed"
            ],
            "fix_deployment_if": [
              "Configuration drift introduced bugs",
              "Security controls missing or misconfigured",
              "Services not deployed as intended"
            ],
            "accept_drift_if": [
              "Environment-specific configuration (expected)",
              "Temporary workarounds for production issues",
              "Optimization for operational efficiency"
            ]
          },
          "output_location": "docs/AS_FIELDED_ARCHITECTURE_RATIONALE.md"
        },
        {
          "action_id": "TO-06-A05",
          "description": "Update as-designed architecture for operational insights",
          "conditional": "If delta analysis reveals design should incorporate fielded learnings",
          "process": [
            "Update service_architecture.json files with operational insights",
            "Regenerate system_of_systems_graph.json",
            "Update operational runbooks if architecture changed",
            "Document changes in version_manifest.json"
          ],
          "purpose": "Feed operational experience back into design phase (continuous improvement)"
        },
        {
          "action_id": "TO-06-A06",
          "description": "Create architecture lifecycle summary",
          "purpose": "Document complete architecture evolution: designed → built → fielded",
          "output_file": "docs/ARCHITECTURE_LIFECYCLE_SUMMARY.md",
          "includes": [
            "Summary of as-designed architecture",
            "Summary of as-built changes and rationale",
            "Summary of as-fielded changes and rationale",
            "Similarity scores (designed vs built, designed vs fielded, built vs fielded)",
            "Lessons learned for future systems",
            "Recommendations for next iteration"
          ]
        }
      ],
      "tools_used": [
        "generate_as_fielded_architecture.py",
        "compare_architectures.py"
      ],
      "outputs": [
        "specs/machine/graphs/system_of_systems_graph_as_fielded.json",
        "specs/machine/graphs/architecture_delta_designed_to_fielded_{date}.json",
        "specs/machine/graphs/architecture_delta_built_to_fielded_{date}.json",
        "docs/AS_FIELDED_ARCHITECTURE_RATIONALE.md",
        "docs/ARCHITECTURE_LIFECYCLE_SUMMARY.md"
      ],
      "gates": [
        {
          "gate_id": "G-TO-06",
          "name": "As-Fielded Architecture Validation",
          "checks": [
            "As-fielded graph generated successfully",
            "All deployed services healthy",
            "Delta reports created",
            "Similarity score >= 0.6 (60% match to designed architecture)",
            "All critical deviations documented with rationale",
            "Architecture lifecycle summary complete"
          ],
          "blocking": false,
          "note": "Non-blocking to allow operational flexibility while maintaining architectural awareness"
        }
      ],
      "next_step": "complete"
    }
  ],
  "completion": {
    "description": "Testing & operations workflow complete - system is production-ready",
    "outputs_summary": [
      "Comprehensive test results (DTE and OTE)",
      "CI/CD pipelines configured and working",
      "Docker Compose and deployment manifests validated",
      "Operational runbooks and procedures",
      "Monitoring and alerting configured",
      "SLOs defined",
      "Release certification report",
      "Production deployment (if approved)"
    ],
    "next_workflow": null,
    "system_status": "PRODUCTION-READY or DEPLOYED",
    "post_release_activities": [
      "Monitor production metrics",
      "Respond to incidents per runbooks",
      "Collect user feedback",
      "Plan future enhancements (return to feature_update workflow if needed)"
    ]
  },
  "llm_agent_guidance": {
    "critical_reminders": [
      "ALWAYS run Docker Compose validation before proceeding to operations",
      "Enforce all quality gates - they prevent production issues",
      "Create comprehensive runbooks - they are critical for operations",
      "Performance testing must validate against SLOs",
      "Security testing is mandatory - block on critical vulnerabilities",
      "Release certification requires stakeholder approval"
    ],
    "common_mistakes": [
      "Skipping Docker Compose validation",
      "Not creating runbooks",
      "Skipping performance testing",
      "Deploying with failing tests",
      "Not configuring monitoring and alerting",
      "Skipping UAT"
    ],
    "quality_gates_mandatory": [
      "G-TO-01: Development Testing Gate",
      "G-TO-03: Deployment Validation Gate",
      "G-TO-05: Release Certification Gate (FINAL GATE)"
    ],
    "final_gate_importance": "Gate G-TO-05 is the FINAL gate before production. Do not skip or bypass this gate under any circumstances."
  }
}
